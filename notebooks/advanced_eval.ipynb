{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('data/processed/cleaned_jobs_tech_aug.csv')\n",
    "    # Assume 'recommended' column (1 if in top-10, 0 else) from recs\n",
    "    df['recommended'] = np.random.randint(0, 2, len(df))  # Synthetic for demo\n",
    "    audit = bias_audit(df)\n",
    "    print(audit)\n",
    "    # Debias example (use your ranking NN)\n",
    "    features = np.random.rand(len(df), 5)  # E.g., embedding sim + features\n",
    "    labels = df['recommended']\n",
    "    sensitive = df['job_level']\n",
    "    mitigator = debias_model(RandomForestClassifier(), features, labels, sensitive)  # Example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(mitigator, 'model/debiased_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.ensemble import RandomForestRegressor  # Proxy for explainer\n",
    "\n",
    "def explain_recs(model, features):\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(features)\n",
    "    shap.summary_plot(shap_values, features, feature_names=['sim_score', 'skill_match', 'location_match'])\n",
    "    return shap_values\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Proxy model (use your ranking NN or RF for demo).\n",
    "    proxy_model = RandomForestRegressor().fit(features, labels)\n",
    "    shap_values = explain_recs(proxy_model, features)\n",
    "    # For output: \"Matches 80% on skills like PyTorch (SHAP +0.5)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks/advanced_eval.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "#from src.embedding_model import generate_embeddings, recommend_jobs  # Import from Step 3\n",
    "#from src.advanced_features import bias_audit, explain_recs  # From Step 4\n",
    "from sklearn.ensemble import RandomForestRegressor  # For proxy if no NN\n",
    "\n",
    "# Load data (adjust paths)\n",
    "df = pd.read_csv('data/processed/cleaned_jobs_tech_aug.csv')\n",
    "job_texts = df['cleaned_summary'].tolist()\n",
    "job_embeddings = np.load('data/processed/job_embeddings.npy')\n",
    "index = faiss.read_index('data/processed/faiss_index.index')\n",
    "\n",
    "# Example resume text\n",
    "resume_text = \"master computer science ml dl pytorch nlp bert hugging face transformers scikit-learn faiss ethical ai bias mitigation fairlearn streamlit\"\n",
    "\n",
    "# Get recommendations\n",
    "recs = recommend_jobs(resume_text, job_texts, df, top_k=10)\n",
    "\n",
    "# Bias audit (add 'recommended' if missing)\n",
    "recs['recommended'] = 1\n",
    "bias_audit(recs)\n",
    "\n",
    "# Explainability (derive features from recs; e.g., sim_score from column, dummy skill/location)\n",
    "rec_features = np.column_stack((recs['similarity_score'], np.random.rand(len(recs), 2)))  # Real: [sim_score, skill_match, location_match]\n",
    "\n",
    "# Define or load model (use proxy RF if no Step 3 NN; or load torch model)\n",
    "proxy_model = RandomForestRegressor().fit(rec_features, recs['recommended'])  # Train proxy on rec data\n",
    "explain_recs(proxy_model, rec_features)  # Use proxy_model instead of 'your_model'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
